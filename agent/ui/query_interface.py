# agent/ui/query_interface.py (–æ–±–Ω–æ–≤–ª—ë–Ω –¥–ª—è –Ω–æ–≤–æ–≥–æ build_sql_from_json –∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è mappings)
import sys
import streamlit as st
import json
import os
import pandas as pd
from pathlib import Path
from sqlalchemy import create_engine, inspect, text
import ollama
import re
import matplotlib.pyplot as plt

current_file_dir = Path(__file__).resolve().parent
project_root = current_file_dir.parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from agent.llm.ollama_client import AnalystLLM
from agent.utils.sql_builder import build_sql_from_json
from agent.utils.knowledge_base import load_knowledge_base, save_knowledge_base_entry
from agent.utils.logger import get_logger

logger = get_logger(__name__)

DB_PATH = project_root / "generated" / "digital_twin.db"
KB_PATH = project_root / "generated" / "knowledge_base.json"

def get_db_schema():
    engine = create_engine(f"sqlite:///{DB_PATH}", future=True)
    inspector = inspect(engine)
    tables = {}
    for table_name in inspector.get_table_names():
        if table_name != "docs":
            columns = [col['name'] for col in inspector.get_columns(table_name)]
            tables[table_name] = columns
    return tables

def show_db_overview():
    st.subheader("–û–±–∑–æ—Ä –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
    schema = get_db_schema()
    if not schema:
        st.error("–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ç–∞–±–ª–∏—Ü –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.")
        return
    st.subheader("–°—Ö–µ–º–∞—Ç–∏—á–Ω—ã–π –≤–∏–¥")
    fig, ax = plt.subplots(figsize=(10, len(schema) * 0.5 + 1))
    ax.set_xlim(0, 10)
    ax.set_ylim(0, len(schema))
    ax.axis('off')
    y_pos = len(schema) - 0.5
    for table_name, columns in schema.items():
        ax.text(0.5, y_pos, f"–¢–∞–±–ª–∏—Ü–∞: {table_name}", fontsize=12, fontweight='bold', verticalalignment='center', bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue"))
        col_y_start = y_pos - 0.3
        for i, col in enumerate(columns):
            ax.text(2.5, col_y_start - i*0.2, f" - {col}", fontsize=10, verticalalignment='top')
        y_pos -= max(len(columns) * 0.2, 1)
    plt.tight_layout()
    st.pyplot(fig)
    plt.close()
    st.subheader("–¢–∞–±–ª–∏—á–Ω—ã–π –≤–∏–¥")
    selected_table_for_view = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∞–±–ª–∏—Ü—É –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –¥–∞–Ω–Ω—ã—Ö:", list(schema.keys()), key="view_data_table")
    if selected_table_for_view:
        engine = create_engine(f"sqlite:///{DB_PATH}", future=True)
        with engine.begin() as conn:
            limit = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è", min_value=1, max_value=1000, value=100, step=10, key="view_data_limit")
            query = text(f"SELECT * FROM \"{selected_table_for_view}\" LIMIT :limit")
            rows = conn.execute(query, {"limit": limit}).fetchall()
            if rows:
                df = pd.DataFrame([dict(row._mapping) for row in rows])
                st.dataframe(df, use_container_width=True)
            else:
                st.info(f"–¢–∞–±–ª–∏—Ü–∞ '{selected_table_for_view}' –ø—É—Å—Ç–∞.")

st.set_page_config(page_title="–¶–∏—Ñ—Ä–æ–≤–æ–π –¥–≤–æ–π–Ω–∏–∫ - –ê–≥–µ–Ω—Ç", page_icon="ü§ñ", layout="wide")
st.title("ü§ñ –¶–∏—Ñ—Ä–æ–≤–æ–π –¥–≤–æ–π–Ω–∏–∫ - –ê–≥–µ–Ω—Ç-–∞–Ω–∞–ª–∏—Ç–∏–∫")

page = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—É:", ["–ê–≥–µ–Ω—Ç-–∞–Ω–∞–ª–∏—Ç–∏–∫", "–û–±–∑–æ—Ä –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"])

if page == "–ê–≥–µ–Ω—Ç-–∞–Ω–∞–ª–∏—Ç–∏–∫":
    schema = get_db_schema()
    if not schema:
        st.error("–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ç–∞–±–ª–∏—Ü –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.")
        st.stop()

    table_names = list(schema.keys())
    selected_table = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∞–±–ª–∏—Ü—É –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Å—Ö–µ–º—ã (–¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–∞):", table_names, key="schema_table")

    if selected_table:
        st.subheader(f"–°—Ö–µ–º–∞ —Ç–∞–±–ª–∏—Ü—ã: `{selected_table}`")
        cols_df = pd.DataFrame(schema[selected_table], columns=["–°—Ç–æ–ª–±–µ—Ü"])
        st.dataframe(cols_df, use_container_width=True, hide_index=True)

    st.markdown("---")
    with st.form(key='query_form'):
        user_question = st.text_input("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å:")
        submit_button = st.form_submit_button(label='–ó–∞–ø—Ä–æ—Å–∏—Ç—å')

    if submit_button and user_question:
        kb = load_knowledge_base()
        relevant_examples = []
        for entry in kb:
            if user_question.lower() in entry.get("question", "").lower() or entry.get("question", "").lower() in user_question.lower():
                relevant_examples.append(entry)

        schema_desc = f"–¢–∞–±–ª–∏—Ü–∞: {selected_table}, –∫–æ–ª–æ–Ω–∫–∏: {', '.join(schema[selected_table])}."
        examples_text = "\n".join([f"–í–æ–ø—Ä–æ—Å: \"{entry['question']}\"\n–û—Ç–≤–µ—Ç: {entry['json_query']}" for entry in relevant_examples[:3]])
        prompt = f"""{examples_text}
        –°—Ö–µ–º–∞ –¥–∞–Ω–Ω—ã—Ö: {schema_desc}.
        –¢—ã - –ø–∞—Ä—Å–µ—Ä –≤–æ–ø—Ä–æ—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å –∏ –≤–µ—Ä–Ω—É—Ç—å JSON-–æ–ø–∏—Å–∞–Ω–∏–µ SQL-–∑–∞–ø—Ä–æ—Å–∞.
        –í–æ–ø—Ä–æ—Å: '{user_question}'
        –§–æ—Ä–º–∞—Ç JSON: {{"select": ["—Å—Ç–æ–ª–±–µ—Ü1", "—Å—Ç–æ–ª–±–µ—Ü2", ...], "distinct": true/false (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ), "from": "–∏–º—è_—Ç–∞–±–ª–∏—Ü—ã", "where": [{{"column": "–∏–º—è_—Å—Ç–æ–ª–±—Ü–∞", "operator": "–æ–ø–µ—Ä–∞—Ç–æ—Ä", "value": "–∑–Ω–∞—á–µ–Ω–∏–µ"}}] (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)}}, "limit": N (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)}}.
        –ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ—à—å –æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ —Å–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å ‚Äî –≤–µ—Ä–Ω–∏ where.column –∫–∞–∫ UNKNOWN_<name>.
        """

        messages = [
            {"role": "system", "content": "–¢—ã - –ø–∞—Ä—Å–µ—Ä –≤–æ–ø—Ä–æ—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –í—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–π —Ç–æ–ª—å–∫–æ JSON-–æ–ø–∏—Å–∞–Ω–∏–µ–º SQL-–∑–∞–ø—Ä–æ—Å–∞."},
            {"role": "user", "content": prompt}
        ]

        try:
            LLM_MODEL = "digital_twin_analyst"
            resp_ollama = ollama.chat(model=LLM_MODEL, messages=messages)
            raw_response = resp_ollama["message"]["content"].strip()
            logger.debug("LLM raw: %s", raw_response)
            json_match = re.search(r'```json\s*(.*?)\s*```|^(.+)$', raw_response, re.DOTALL)
            if json_match:
                extracted_json_str = json_match.group(1) if json_match.group(1) else json_match.group(2)
                if extracted_json_str:
                    raw_response = extracted_json_str.strip()
            try:
                generated_json_query = json.loads(raw_response)
            except json.JSONDecodeError as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM: {e}")
                with st.expander("Raw LLM response"):
                    st.code(raw_response, language="text")
                generated_json_query = None
            st.subheader("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π JSON:")
            st.json(generated_json_query)

            try:
                final_sql, params, mappings = build_sql_from_json(generated_json_query, DB_PATH)
                if mappings.get("unknowns"):
                    with st.expander("‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç—Å—è —É—Ç–æ—á–Ω–µ–Ω–∏–µ (unknowns)"):
                        st.write("–ü–æ–ª—è, —Ç—Ä–µ–±—É—é—â–∏–µ —É—Ç–æ—á–Ω–µ–Ω–∏—è:")
                        for unk in mappings["unknowns"]:
                            st.write(f"- {unk}")
                if mappings.get("replacements"):
                    with st.expander("‚ÑπÔ∏è –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–º–µ–Ω—ã"):
                        for orig, mapped in mappings["replacements"].items():
                            st.write(f"`{orig}` ‚Üí `{mapped}`")
                if final_sql:
                    engine = create_engine(f"sqlite:///{DB_PATH}", future=True)
                    with engine.begin() as conn:
                        rows = conn.execute(text(final_sql), params).fetchall()
                        data = [dict(r._mapping) for r in rows]
                        if data:
                            df = pd.DataFrame(data)
                            st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∑–∞–ø—Ä–æ—Å–∞:")
                            st.dataframe(df, use_container_width=True)
                        else:
                            st.info("–ó–∞–ø—Ä–æ—Å –Ω–µ –≤–µ—Ä–Ω—É–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.")
                    st.subheader("–í—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã–π SQL:")
                    st.code(final_sql, language="sql")
                    st.write(f"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {params}")
                else:
                    st.warning("SQL –Ω–µ –±—ã–ª —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –∏–∑-–∑–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ø–æ–ª–µ–π.")
            except Exception as e_sql:
                st.error(f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è SQL: {e_sql}")
                st.code(str(e_sql), language="text")

        except json.JSONDecodeError as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM: {e}")
            st.code(raw_response, language="text")
        except Exception as e_gen:
            st.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–ª–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞: {e_gen}")
            st.code(str(e_gen), language="text")

    st.subheader("–ò—Å–ø—Ä–∞–≤–∏—Ç—å JSON (–µ—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ–≤–µ—Ä–µ–Ω):")
    corrected_json_str = st.text_area("–í–≤–µ–¥–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π JSON:", value=json.dumps(generated_json_query, ensure_ascii=False, indent=2) if 'generated_json_query' in locals() else "", height=300)
    if st.button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ"):
        try:
            corrected_json_obj = json.loads(corrected_json_str)
            save_knowledge_base_entry(user_question, corrected_json_str)
            try:
                final_sql, params, mappings = build_sql_from_json(corrected_json_obj, DB_PATH)
                if final_sql:
                    engine = create_engine(f"sqlite:///{DB_PATH}", future=True)
                    with engine.begin() as conn:
                        rows = conn.execute(text(final_sql), params).fetchall()
                        data = [dict(r._mapping) for r in rows]
                    st.success("–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∏ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
                    if data:
                        df = pd.DataFrame(data)
                        st.dataframe(df, use_container_width=True)
                else:
                    st.warning("–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ, –Ω–æ SQL –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω (–≤–æ–∑–º–æ–∂–Ω–æ, –µ—Å—Ç—å UNKNOWN-–ø–æ–ª—è).")
            except Exception as e_test:
                st.warning(f"–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ, –Ω–æ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–æ–≤–æ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏: {e_test}")
        except json.JSONDecodeError:
            st.error("–í–≤–µ–¥—ë–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º JSON.")

elif page == "–û–±–∑–æ—Ä –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö":
    show_db_overview()

if __name__ == "__main__":
    st.write("–ó–∞–ø—É—Å—Ç–∏—Ç–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å: streamlit run agent/ui/query_interface.py")