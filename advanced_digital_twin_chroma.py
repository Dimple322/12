#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ü–†–û–î–£–ö–¢–ò–í–ù–ê–Ø –≤–µ—Ä—Å–∏—è —Å–∏—Å—Ç–µ–º—ã —Ü–∏—Ñ—Ä–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ —Å ChromaDB.
–ü–æ–ª–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å ChromaDB, –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏, —É–ª—É—á—à–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö.
"""

from __future__ import annotations
from dataclasses import dataclass, field, asdict
from pathlib import Path
from typing import List, Dict, Optional, Any, Callable
import json
import re
import time
import asyncio
import sqlite3
from datetime import datetime
from enum import Enum
import logging

# ChromaDB –∏–º–ø–æ—Ä—Ç—ã
import chromadb
from chromadb.config import Settings
from chromadb.utils import embedding_functions

# AI –∏ ML
import ollama
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from gpu_embed_global import GpuMiniLMEmbedding   # ‚Üê –Ω–∞—à–∞ GPU-–æ–±—ë—Ä—Ç–∫–∞


# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –ø—Ä–æ–¥—É–∫—Ç–∞
LLM_MODEL = "digital_twin_analyst"
CHROMA_PATH = Path("generated/chroma_db")
KNOWLEDGE_BASE_PATH = Path("generated/knowledge_base_productive.json")
SCENARIOS_PATH = Path("generated/scenarios")
EMBEDDING_MODEL = "all-MiniLM-L6-v2"


class QueryType(Enum):
    ANALYTICS = "analytics"
    SCENARIO = "scenario"
    PREDICTION = "prediction"
    VALIDATION = "validation"
    EXPLANATION = "explanation"

    def __str__(self):
        return self.value


@dataclass
class Context:
    """–ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏"""
    session_id: str
    user_id: str
    previous_queries: List[Dict] = field(default_factory=list)
    domain_knowledge: Dict[str, Any] = field(default_factory=dict)
    preferences: Dict[str, Any] = field(default_factory=dict)
    timestamp: datetime = field(default_factory=datetime.now)

    def to_dict(self):
        return {
            "session_id": self.session_id,
            "user_id": self.user_id,
            "previous_queries": self.previous_queries,
            "domain_knowledge": self.domain_knowledge,
            "preferences": self.preferences,
            "timestamp": self.timestamp.isoformat()
        }


@dataclass
class ReasoningStep:
    """–®–∞–≥ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π"""
    step_number: int
    description: str
    reasoning: str
    action: str
    expected_outcome: str
    actual_outcome: Optional[str] = None
    confidence: float = 0.0
    validation_passed: bool = False

    def to_dict(self):
        return {
            "step_number": self.step_number,
            "description": self.description,
            "reasoning": self.reasoning,
            "action": self.action,
            "expected_outcome": self.expected_outcome,
            "actual_outcome": self.actual_outcome,
            "confidence": self.confidence,
            "validation_passed": self.validation_passed
        }


@dataclass
class AnalysisResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏"""
    query: str
    chroma_query: str
    data: List[Dict]
    reasoning_steps: List[ReasoningStep]
    insights: List[str]
    recommendations: List[str]
    confidence_score: float
    validation_results: Dict[str, Any]
    scenario_analysis: Optional[Dict[str, Any]] = None
    timestamp: datetime = field(default_factory=datetime.now)

    def to_dict(self):
        return {
            "query": self.query,
            "chroma_query": self.chroma_query,
            "data": self.data,
            "reasoning_steps": [step.to_dict() for step in self.reasoning_steps],
            "insights": self.insights,
            "recommendations": self.recommendations,
            "confidence_score": self.confidence_score,
            "validation_results": self.validation_results,
            "scenario_analysis": self.scenario_analysis,
            "timestamp": self.timestamp.isoformat()
        }


class ChromaDBManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å ChromaDB"""

    def __init__(self, persist_directory: Path = CHROMA_PATH):
        self.persist_directory = persist_directory
        self.persist_directory.mkdir(parents=True, exist_ok=True)

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ ChromaDB
        self.client = chromadb.PersistentClient(path=str(self.persist_directory))

        from sentence_transformers import SentenceTransformer
        import torch

        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        st_model = SentenceTransformer(EMBEDDING_MODEL, device=device)  # ‚Üê GPU

        from sentence_transformers import SentenceTransformer
        import torch

        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        st_model = SentenceTransformer(EMBEDDING_MODEL, device=device)  # ‚Üê GPU

        from gpu_embed_global import gpu_embedding
        self.embedding_function = gpu_embedding

        # –ö–æ–ª–ª–µ–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö
        self.collections = {}
        self._initialize_collections()

    def _initialize_collections(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–ª–ª–µ–∫—Ü–∏–∏ ChromaDB"""

        # –û—Å–Ω–æ–≤–Ω–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        self.collections['documents'] = self.client.get_or_create_collection(
            name="documents",
            embedding_function=self.embedding_function,
            metadata={"hnsw:space": "cosine"}
        )

        # –ö–æ–ª–ª–µ–∫—Ü–∏—è –¥–ª—è —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
        self.collections['scenarios'] = self.client.get_or_create_collection(
            name="scenarios",
            embedding_function=self.embedding_function,
            metadata={"hnsw:space": "cosine"}
        )

        # –ö–æ–ª–ª–µ–∫—Ü–∏—è –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∑–∞–ø—Ä–æ—Å–æ–≤
        self.collections['queries'] = self.client.get_or_create_collection(
            name="queries",
            embedding_function=self.embedding_function,
            metadata={"hnsw:space": "cosine"}
        )

        # –ö–æ–ª–ª–µ–∫—Ü–∏—è –¥–ª—è –∏–Ω—Å–∞–π—Ç–æ–≤
        self.collections['insights'] = self.client.get_or_create_collection(
            name="insights",
            embedding_function=self.embedding_function,
            metadata={"hnsw:space": "cosine"}
        )

    def add_documents(self, documents: List[str], metadatas: List[Dict], ids: List[str],
                      collection_name: str = 'documents'):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é"""
        try:
            self.collections[collection_name].add(
                documents=documents,
                metadatas=metadatas,
                ids=ids
            )
            logger.info(f"Added {len(documents)} documents to {collection_name} collection")
        except Exception as e:
            logger.error(f"Error adding documents to {collection_name}: {e}")

    def query_documents(self, query_text: str, n_results: int = 10, collection_name: str = 'documents',
                        filter_dict: Dict = None):
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        try:
            results = self.collections[collection_name].query(
                query_texts=[query_text],
                n_results=n_results,
                where=filter_dict
            )
            return results
        except Exception as e:
            logger.error(f"Error querying documents from {collection_name}: {e}")
            return {'documents': [[]], 'metadatas': [[]], 'distances': [[]]}

    def get_all_documents(self, collection_name: str = 'documents'):
        """–ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ –∫–æ–ª–ª–µ–∫—Ü–∏–∏"""
        try:
            results = self.collections[collection_name].get()
            return results
        except Exception as e:
            logger.error(f"Error getting all documents from {collection_name}: {e}")
            return {'documents': [], 'metadatas': [], 'ids': []}

    def update_document(self, document_id: str, document: str, metadata: Dict, collection_name: str = 'documents'):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏"""
        try:
            self.collections[collection_name].update(
                ids=[document_id],
                documents=[document],
                metadatas=[metadata]
            )
            logger.info(f"Updated document {document_id} in {collection_name} collection")
        except Exception as e:
            logger.error(f"Error updating document in {collection_name}: {e}")

    def delete_document(self, document_id: str, collection_name: str = 'documents'):
        """–£–¥–∞–ª—è–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –∏–∑ –∫–æ–ª–ª–µ–∫—Ü–∏–∏"""
        try:
            self.collections[collection_name].delete(ids=[document_id])
            logger.info(f"Deleted document {document_id} from {collection_name} collection")
        except Exception as e:
            logger.error(f"Error deleting document from {collection_name}: {e}")


class AdvancedDigitalTwin:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è —Å–∏—Å—Ç–µ–º–∞ —Ü–∏—Ñ—Ä–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ —Å ChromaDB"""

    def __init__(self):
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ChromaDB
        self.chroma_manager = ChromaDBManager()

        # –ê–≥–µ–Ω—Ç—ã —Å–∏—Å—Ç–µ–º—ã
        self.context_agent = ContextAgent(self.chroma_manager)
        self.reasoning_agent = ReasoningAgent(self.chroma_manager)
        self.data_agent = DataAgent(self.chroma_manager)
        self.validation_agent = ValidationAgent(self.chroma_manager)
        self.scenario_agent = DynamicScenarioAgent(self.chroma_manager)
        self.explanation_agent = ExplanationAgent(self.chroma_manager)

        # –•—Ä–∞–Ω–∏–ª–∏—â–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤
        self.contexts: Dict[str, Context] = {}

        # –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π
        self.knowledge_base = self._load_knowledge_base()

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–¥—É–∫—Ç–∞
        self._initialize_product()

    def _initialize_product(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω—É—é —Å–∏—Å—Ç–µ–º—É"""
        print("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–¥—É–∫—Ç–∞ —Å ChromaDB...")

        # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
        SCENARIOS_PATH.mkdir(parents=True, exist_ok=True)

        # –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–∞—á–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –µ—Å–ª–∏ –µ—Å—Ç—å
        self._load_initial_data()

        print("‚úÖ –ü—Ä–æ–¥—É–∫—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    def _load_initial_data(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –Ω–∞—á–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ ChromaDB"""
        # –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–∞—Å—Ç—Ä–æ–µ–Ω –ø–æ–¥ –≤–∞—à–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        # –ü—Ä–∏–º–µ—Ä –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ —Ñ–∞–π–ª–æ–≤ –∏–ª–∏ API
        pass

    def _load_knowledge_base(self) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –±–∞–∑—É –∑–Ω–∞–Ω–∏–π"""
        if KNOWLEDGE_BASE_PATH.exists():
            with open(KNOWLEDGE_BASE_PATH, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {"patterns": [], "scenarios": [], "validations": [], "user_queries": []}

    def _save_knowledge_base(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –±–∞–∑—É –∑–Ω–∞–Ω–∏–π"""
        with open(KNOWLEDGE_BASE_PATH, 'w', encoding='utf-8') as f:
            json.dump(self.knowledge_base, f, ensure_ascii=False, indent=2)

    async def process_query(self, query: str, session_id: str = "default",
                            query_type: QueryType = QueryType.ANALYTICS) -> AnalysisResult:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å —Å –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–º Reasoning"""

        logger.info(f"Processing query: {query} (type: {query_type.value})")

        # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–ª–∏ —Å–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        context = self.contexts.get(session_id, Context(session_id=session_id, user_id="user"))

        # –®–∞–≥ 1: –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞
        reasoning_steps = []

        step1 = ReasoningStep(
            step_number=1,
            description="–ê–Ω–∞–ª–∏–∑ —Ç–∏–ø–∞ –∑–∞–ø—Ä–æ—Å–∞ –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏",
            reasoning=self._determine_query_strategy(query, query_type),
            action="–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –∑–∞–ø—Ä–æ—Å–∞ –∏ –ø–æ–¥—Ö–æ–¥—è—â–µ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏",
            expected_outcome="–ß–µ—Ç–∫–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ —Ü–µ–ª–∏ –∑–∞–ø—Ä–æ—Å–∞ –∏ –≤—ã–±–æ—Ä –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –ø—É—Ç–∏ —Ä–µ—à–µ–Ω–∏—è"
        )
        reasoning_steps.append(step1)

        try:
            # –®–∞–≥ 2: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –∏—Å—Ç–æ—Ä–∏–∏
            relevant_context = await self.context_agent.extract_relevant_context(query, context)

            step2 = ReasoningStep(
                step_number=2,
                description="–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞",
                reasoning=f"–ù–∞–π–¥–µ–Ω–æ {len(relevant_context)} –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤",
                action="–ê–Ω–∞–ª–∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏",
                expected_outcome="–ö–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞"
            )
            reasoning_steps.append(step2)

            # –®–∞–≥ 3: –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ—à–µ–Ω–∏—è
            if query_type == QueryType.SCENARIO:
                solution_plan = await self.scenario_agent.plan_scenario_analysis(query, context)
            else:
                solution_plan = await self.reasoning_agent.create_solution_plan(query, context, relevant_context)

            step3 = ReasoningStep(
                step_number=3,
                description="–°–æ–∑–¥–∞–Ω–∏–µ –ø–ª–∞–Ω–∞ —Ä–µ—à–µ–Ω–∏—è",
                reasoning=solution_plan["reasoning"],
                action="–†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –ø–æ—à–∞–≥–æ–≤–æ–≥–æ –ø–ª–∞–Ω–∞ –∞–Ω–∞–ª–∏–∑–∞",
                expected_outcome="–ß–µ—Ç–∫–∏–π –ø–ª–∞–Ω –¥–µ–π—Å—Ç–≤–∏–π –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Ü–µ–ª–∏ –∑–∞–ø—Ä–æ—Å–∞"
            )
            reasoning_steps.append(step3)

            # –®–∞–≥ 4: –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞
            if query_type == QueryType.SCENARIO:
                result = await self.scenario_agent.execute_scenario_analysis(query, solution_plan, context)
            else:
                result = await self._execute_analytics_query(query, solution_plan, context)

            step4 = ReasoningStep(
                step_number=4,
                description="–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞",
                reasoning=f"–í—ã–ø–æ–ª–Ω–µ–Ω–æ {len(result.data)} –∑–∞–ø–∏—Å–µ–π",
                action="–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ ChromaDB –∑–∞–ø—Ä–æ—Å–∞ –∏ –ø–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö",
                expected_outcome="–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞",
                actual_outcome=f"–ü–æ–ª—É—á–µ–Ω–æ {len(result.data)} –∑–∞–ø–∏—Å–µ–π",
                confidence=0.8
            )
            reasoning_steps.append(step4)

            # –®–∞–≥ 5: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–Ω—Å–∞–π—Ç–æ–≤ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ)
            if result.data:
                insights = await self.explanation_agent.generate_insights(result, context)

                step5 = ReasoningStep(
                    step_number=5,
                    description="–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–Ω—Å–∞–π—Ç–æ–≤ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π",
                    reasoning=f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(insights)} –∏–Ω—Å–∞–π—Ç–æ–≤",
                    action="–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –∏–Ω—Å–∞–π—Ç–æ–≤",
                    expected_outcome="–ü–æ–Ω–∏–º–∞–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∏ —Ç—Ä–µ–Ω–¥–æ–≤ –≤ –¥–∞–Ω–Ω—ã—Ö",
                    actual_outcome=f"–ù–∞–π–¥–µ–Ω–æ {len(insights)} –∫–ª—é—á–µ–≤—ã—Ö –∏–Ω—Å–∞–π—Ç–æ–≤",
                    confidence=0.75
                )
                reasoning_steps.append(step5)

                # –û–±–Ω–æ–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –∏–Ω—Å–∞–π—Ç–∞–º–∏
                result.insights = insights.get("insights", [])
                result.recommendations = insights.get("recommendations", [])

            # –®–∞–≥ 6: –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            validation_results = await self.validation_agent.validate_results(result, context)

            step6 = ReasoningStep(
                step_number=6,
                description="–í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤",
                reasoning=f"–í–∞–ª–∏–¥–∞—Ü–∏—è {'–ø—Ä–æ–π–¥–µ–Ω–∞' if validation_results['is_valid'] else '–Ω–µ –ø—Ä–æ–π–¥–µ–Ω–∞'}",
                action="–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏ –≤—ã—è–≤–ª–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π",
                expected_outcome="–ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤",
                actual_outcome=validation_results["summary"],
                confidence=validation_results["confidence"],
                validation_passed=validation_results["is_valid"]
            )
            reasoning_steps.append(step6)

            # –®–∞–≥ 7: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ (–µ—Å–ª–∏ –∑–∞–ø—Ä–æ—à–µ–Ω–æ)
            scenario_analysis = None
            if query_type == QueryType.SCENARIO and result.data:
                scenario_analysis = await self.scenario_agent.generate_dynamic_scenarios(query, result, context)

                step7 = ReasoningStep(
                    step_number=7,
                    description="–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤",
                    reasoning=f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(scenario_analysis.get('scenarios', []))} —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤",
                    action="–ê–Ω–∞–ª–∏–∑ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤",
                    expected_outcome="–ü–æ–Ω–∏–º–∞–Ω–∏–µ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ —Ä–∞–∑–≤–∏—Ç–∏—è",
                    actual_outcome=f"–†–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–æ {len(scenario_analysis.get('scenarios', []))} —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤",
                    confidence=0.7
                )
                reasoning_steps.append(step7)

            # –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            final_result = AnalysisResult(
                query=query,
                chroma_query=result.chroma_query,
                data=result.data,
                reasoning_steps=reasoning_steps,
                insights=result.insights,
                recommendations=result.recommendations,
                confidence_score=np.mean([step.confidence for step in reasoning_steps]),
                validation_results=validation_results,
                scenario_analysis=scenario_analysis
            )

            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            context.previous_queries.append({
                "query": query,
                "result": final_result.to_dict(),
                "timestamp": datetime.now()
            })
            self.contexts[session_id] = context

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π
            self._update_knowledge_base(query, final_result)

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –≤ ChromaDB –¥–ª—è –±—É–¥—É—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            await self._save_query_to_chroma(query, final_result)

            return final_result

        except Exception as e:
            logger.error(f"Error processing query: {e}")

            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –æ—à–∏–±–∫–æ–π
            return AnalysisResult(
                query=query,
                chroma_query="",
                data=[],
                reasoning_steps=reasoning_steps,
                insights=[f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}"],
                recommendations=["–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å"],
                confidence_score=0.0,
                validation_results={"is_valid": False, "confidence": 0.0, "error": str(e)}
            )

    def _determine_query_strategy(self, query: str, query_type: QueryType) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞"""
        if query_type == QueryType.SCENARIO:
            return "–ó–∞–ø—Ä–æ—Å —Ç—Ä–µ–±—É–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞"
        elif query_type == QueryType.PREDICTION:
            return "–ó–∞–ø—Ä–æ—Å —Ç—Ä–µ–±—É–µ—Ç –ø—Ä–µ–¥–∏–∫—Ç–∏–≤–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –∏ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö"
        elif query_type == QueryType.VALIDATION:
            return "–ó–∞–ø—Ä–æ—Å —Ç—Ä–µ–±—É–µ—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –≥–∏–ø–æ—Ç–µ–∑"
        else:
            return "–ó–∞–ø—Ä–æ—Å —Ç—Ä–µ–±—É–µ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ —Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –∏–Ω—Å–∞–π—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö ChromaDB"

    async def _execute_analytics_query(self, query: str, solution_plan: Dict, context: Context) -> AnalysisResult:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ ChromaDB"""
        try:
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è ChromaDB –∑–∞–ø—Ä–æ—Å–∞
            chroma_query = await self.data_agent.generate_chroma_query(query, solution_plan, context)

            # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞
            data = await self.data_agent.execute_chroma_query(chroma_query)

            return AnalysisResult(
                query=query,
                chroma_query=chroma_query,
                data=data,
                reasoning_steps=[],
                insights=[],
                recommendations=[],
                confidence_score=0.8,
                validation_results={"is_valid": True, "confidence": 0.8}
            )
        except Exception as e:
            logger.error(f"Error in analytics query execution: {e}")
            return AnalysisResult(
                query=query,
                chroma_query="",
                data=[],
                reasoning_steps=[],
                insights=[f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {str(e)}"],
                recommendations=[],
                confidence_score=0.0,
                validation_results={"is_valid": False, "confidence": 0.0, "error": str(e)}
            )

    def _update_knowledge_base(self, query: str, result: AnalysisResult):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –Ω–æ–≤—ã–º–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏"""
        try:
            pattern = {
                "query_pattern": query,
                "query_type": "analytics",
                "successful_steps": [step.description for step in result.reasoning_steps if step.validation_passed],
                "insights": result.insights,
                "confidence": result.confidence_score,
                "timestamp": datetime.now().isoformat()
            }

            self.knowledge_base["patterns"].append(pattern)

            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
            if len(self.knowledge_base["patterns"]) > 1000:
                self.knowledge_base["patterns"] = self.knowledge_base["patterns"][-500:]

            self._save_knowledge_base()
        except Exception as e:
            logger.error(f"Error updating knowledge base: {e}")

    async def _save_query_to_chroma(self, query: str, result: AnalysisResult):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∑–∞–ø—Ä–æ—Å –≤ ChromaDB –¥–ª—è –±—É–¥—É—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
        try:
            # –°–æ–∑–¥–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            document = f"Query: {query}\n"
            document += f"Insights: {', '.join(result.insights[:3])}\n"
            document += f"Recommendations: {', '.join(result.recommendations[:2])}\n"
            document += f"Data count: {len(result.data)}\n"

            # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            metadata = {
                "query": query,
                "timestamp": datetime.now().isoformat(),
                "confidence": result.confidence_score,
                "data_count": len(result.data),
                "query_type": "analytics"
            }

            # ID –¥–æ–∫—É–º–µ–Ω—Ç–∞
            doc_id = f"query_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{hash(query) % 10000}"

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ ChromaDB
            self.chroma_manager.add_documents(
                documents=[document],
                metadatas=[metadata],
                ids=[doc_id],
                collection_name='queries'
            )

        except Exception as e:
            logger.error(f"Error saving query to ChromaDB: {e}")


class ContextAgent:
    """–ê–≥–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∏ –∏—Å—Ç–æ—Ä–∏–µ–π"""

    def __init__(self, chroma_manager: ChromaDBManager):
        self.chroma_manager = chroma_manager

    async def extract_relevant_context(self, query: str, context: Context) -> List[Dict]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤ —á–µ—Ä–µ–∑ ChromaDB"""
        relevant_context = []

        # –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ ChromaDB
        similar_queries = self.chroma_manager.query_documents(
            query_text=query,
            n_results=5,
            collection_name='queries'
        )

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if similar_queries['documents'] and similar_queries['documents'][0]:
            for i, (doc, metadata) in enumerate(zip(similar_queries['documents'][0], similar_queries['metadatas'][0])):
                relevance_score = 1.0 - similar_queries['distances'][0][i] if similar_queries['distances'][0] else 0.5

                relevant_context.append({
                    "query": metadata.get("query", ""),
                    "relevance_score": relevance_score,
                    "insights": metadata.get("insights", []),
                    "confidence": metadata.get("confidence", 0.5)
                })

        # –¢–∞–∫–∂–µ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞–ø—Ä–æ—Å—ã –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        recent_queries = context.previous_queries[-5:]

        for prev_query in recent_queries:
            # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
            prev_text = prev_query["query"].lower()
            current_text = query.lower()

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—â–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
            common_words = set(prev_text.split()) & set(current_text.split())
            relevance_score = len(common_words) / max(len(prev_text.split()), 1)

            if relevance_score > 0.2:  # –ü–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
                relevant_context.append({
                    "query": prev_query["query"],
                    "relevance_score": relevance_score,
                    "insights": prev_query.get("result", {}).get("insights", [])
                })

        return sorted(relevant_context, key=lambda x: x["relevance_score"], reverse=True)


class ReasoningAgent:
    """–ê–≥–µ–Ω—Ç –¥–ª—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –∏ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è"""

    def __init__(self, chroma_manager: ChromaDBManager):
        self.chroma_manager = chroma_manager

    async def create_solution_plan(self, query: str, context: Context, relevant_context: List[Dict]) -> Dict:
        """–°–æ–∑–¥–∞–µ—Ç –ø–ª–∞–Ω —Ä–µ—à–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–ø—Ä–æ—Å–∞"""

        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ ChromaDB
        available_collections = list(self.chroma_manager.collections.keys())

        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM —Å —É—á–µ—Ç–æ–º –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        prompt = f"""
        –°–æ–∑–¥–∞–π –¥–µ—Ç–∞–ª—å–Ω—ã–π –ø–ª–∞–Ω —Ä–µ—à–µ–Ω–∏—è –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞:

        –ó–∞–ø—Ä–æ—Å: {query}

        –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {available_collections}

        –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤:
        {json.dumps(relevant_context[:3], ensure_ascii=False, indent=2)}

        –ü–ª–∞–Ω –¥–æ–ª–∂–µ–Ω –≤–∫–ª—é—á–∞—Ç—å:
        1. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–∏ –∞–Ω–∞–ª–∏–∑–∞
        2. –í—ã–±–æ—Ä –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–æ–ª–ª–µ–∫—Ü–∏–π –¥–∞–Ω–Ω—ã—Ö
        3. –ü–æ—à–∞–≥–æ–≤—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        4. –ú–µ—Ç–æ–¥—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        5. –ü–æ–¥—Ö–æ–¥ –∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–Ω—Å–∞–π—Ç–æ–≤
        6. –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

        –û—Ç–≤–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
        {{
            "reasoning": "–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –≤—ã–±—Ä–∞–Ω–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏",
            "target_collections": ["–∫–æ–ª–ª–µ–∫—Ü–∏–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"],
            "steps": [
                {{
                    "step": "–û–ø–∏—Å–∞–Ω–∏–µ —à–∞–≥–∞",
                    "purpose": "–¶–µ–ª—å —à–∞–≥–∞",
                    "expected_result": "–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç"
                }}
            ],
            "validation_approach": "–º–µ—Ç–æ–¥ –≤–∞–ª–∏–¥–∞—Ü–∏–∏",
            "scenario_potential": "–ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"
        }}
        """

        try:
            response = ollama.chat(model=LLM_MODEL, messages=[
                {"role": "system",
                 "content": "–¢—ã - —Å—Ç—Ä–∞—Ç–µ–≥ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏. –°–æ–∑–¥–∞–≤–∞–π –¥–µ—Ç–∞–ª—å–Ω—ã–µ –ø–ª–∞–Ω—ã —Ä–µ—à–µ–Ω–∏—è –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å ChromaDB."},
                {"role": "user", "content": prompt}
            ])

            plan_text = response["message"]["content"]

            # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
            json_match = re.search(r'```json\s*(.*?)\s*```', plan_text, re.DOTALL)
            if json_match:
                plan_data = json.loads(json_match.group(1))
            else:
                # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ JSON –Ω–∞–ø—Ä—è–º—É—é
                json_start = plan_text.find('{')
                json_end = plan_text.rfind('}') + 1
                if json_start >= 0 and json_end > json_start:
                    plan_data = json.loads(plan_text[json_start:json_end])
                else:
                    # –ë–∞–∑–æ–≤—ã–π –ø–ª–∞–Ω
                    plan_data = {
                        "reasoning": "–ë–∞–∑–æ–≤—ã–π –ø–ª–∞–Ω –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è ChromaDB",
                        "target_collections": ["documents"],
                        "steps": [{"step": "–í—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å", "purpose": "–ü–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ",
                                   "expected_result": "–î–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"}],
                        "validation_approach": "–±–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞",
                        "scenario_potential": "—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏"
                    }

            return plan_data

        except Exception as e:
            logger.error(f"Error creating solution plan: {e}")
            return {
                "reasoning": "–ë–∞–∑–æ–≤—ã–π –ø–ª–∞–Ω –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏",
                "target_collections": ["documents"],
                "steps": [{"step": "–í—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å", "purpose": "–ü–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ",
                           "expected_result": "–î–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"}],
                "validation_approach": "–±–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞",
                "scenario_potential": "—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏"
            }


class DataAgent:
    """–ê–≥–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –¥–∞–Ω–Ω—ã–º–∏ —á–µ—Ä–µ–∑ ChromaDB"""

    def __init__(self, chroma_manager: ChromaDBManager):
        self.chroma_manager = chroma_manager

    async def generate_chroma_query(self, query: str, solution_plan: Dict, context: Context) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è ChromaDB"""

        target_collections = solution_plan.get("target_collections", ["documents"])

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
        main_collection = target_collections[0] if target_collections else "documents"

        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è ChromaDB
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–ª–æ–≤–∞ –∏ —Ñ–æ–∫—É—Å–∏—Ä—É–µ–º—Å—è –Ω–∞ –∫–ª—é—á–µ–≤—ã—Ö –ø–æ–Ω—è—Ç–∏—è—Ö
        optimized_query = re.sub(r'^(–ø–æ–∫–∞–∂–∏|—Å–∫–æ–ª—å–∫–æ|–∫–∞–∫–∏–µ|–Ω–∞–π–¥–∏)\s+', '', query.lower())
        optimized_query = re.sub(r'[?.,!]', '', optimized_query)

        logger.info(f"Generated ChromaDB query: {optimized_query} for collection: {main_collection}")

        return optimized_query

    async def execute_chroma_query(self, chroma_query: str, collection_name: str = "documents", n_results: int = 20) -> \
    List[Dict]:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–ø—Ä–æ—Å –≤ ChromaDB –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"""
        try:
            # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –≤ ChromaDB
            results = self.chroma_manager.query_documents(
                query_text=chroma_query,
                n_results=n_results,
                collection_name=collection_name
            )

            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —É–¥–æ–±–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
            formatted_results = []

            if results['documents'] and results['documents'][0]:
                for i, (doc, metadata) in enumerate(zip(results['documents'][0], results['metadatas'][0])):
                    distance = results['distances'][0][i] if results['distances'][0] else 0
                    similarity = 1.0 - distance  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –≤ —Å—Ö–æ–¥—Å—Ç–≤–æ

                    formatted_result = {
                        "id": metadata.get("id", f"doc_{i}"),
                        "content": doc,
                        "metadata": metadata,
                        "similarity": similarity,
                        "distance": distance
                    }
                    formatted_results.append(formatted_result)

            logger.info(f"ChromaDB query executed successfully, returned {len(formatted_results)} results")
            return formatted_results

        except Exception as e:
            logger.error(f"Error executing ChromaDB query: {e}")

            # –í–æ–∑–≤—Ä–∞—Ç –ø—É—Å—Ç–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∏–ª–∏ fallback
            return []


class ValidationAgent:
    """–ê–≥–µ–Ω—Ç –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""

    def __init__(self, chroma_manager: ChromaDBManager):
        self.chroma_manager = chroma_manager

    async def validate_results(self, result: AnalysisResult, context: Context) -> Dict[str, Any]:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞"""

        validation_results = {
            "is_valid": True,
            "confidence": 0.8,
            "summary": "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ—à–ª–∏ –±–∞–∑–æ–≤—É—é –≤–∞–ª–∏–¥–∞—Ü–∏—é",
            "checks": []
        }

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ 1: –ï—Å—Ç—å –ª–∏ –¥–∞–Ω–Ω—ã–µ
        has_data = len(result.data) > 0
        validation_results["checks"].append({
            "check": "–ù–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö",
            "passed": has_data,
            "details": f"–ù–∞–π–¥–µ–Ω–æ {len(result.data)} –∑–∞–ø–∏—Å–µ–π"
        })

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ 2: –ö–∞—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ChromaDB
        if has_data:
            avg_similarity = np.mean([item.get("similarity", 0) for item in result.data])
            validation_results["checks"].append({
                "check": "–ö–∞—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ChromaDB",
                "passed": avg_similarity > 0.5,
                "details": f"–°—Ä–µ–¥–Ω—è—è —Å—Ö–æ–∂–µ—Å—Ç—å: {avg_similarity:.3f}"
            })

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ 3: –†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –¥–∞–Ω–Ω—ã—Ö
        if has_data and len(result.data) > 1:
            unique_contents = len(set([item.get("content", "") for item in result.data]))
            validation_results["checks"].append({
                "check": "–†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –¥–∞–Ω–Ω—ã—Ö",
                "passed": unique_contents > 1,
                "details": f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {unique_contents} –∏–∑ {len(result.data)}"
            })

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ 4: –õ–æ–≥–∏—á–µ—Å–∫–∞—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å
        logical_check = self._check_logical_consistency(result)
        validation_results["checks"].append(logical_check)

        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        failed_checks = [check for check in validation_results["checks"] if not check["passed"]]
        validation_results["is_valid"] = len(failed_checks) == 0
        validation_results["confidence"] = 1.0 - (len(failed_checks) / len(validation_results["checks"])) * 0.5

        if failed_checks:
            validation_results[
                "summary"] = f"–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã: {', '.join([check['check'] for check in failed_checks])}"

        return validation_results

    def _check_logical_consistency(self, result: AnalysisResult) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ª–æ–≥–∏—á–µ—Å–∫—É—é –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        # –ë–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ª–æ–≥–∏–∫–∏
        if len(result.data) == 0:
            return {
                "check": "–õ–æ–≥–∏—á–µ—Å–∫–∞—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å",
                "passed": False,
                "details": "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ª–æ–≥–∏–∫–∏"
            }

        return {
            "check": "–õ–æ–≥–∏—á–µ—Å–∫–∞—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å",
            "passed": True,
            "details": "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ª–æ–≥–∏—á–µ—Å–∫–∏ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã"
        }


class DynamicScenarioAgent:
    """–ê–≥–µ–Ω—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤"""

    def __init__(self, chroma_manager: ChromaDBManager):
        self.chroma_manager = chroma_manager

    async def plan_scenario_analysis(self, query: str, context: Context) -> Dict:
        """–ü–ª–∞–Ω–∏—Ä—É–µ—Ç –∞–Ω–∞–ª–∏–∑ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""

        # –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç —Å—Ü–µ–Ω–∞—Ä–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        scenario_elements = self._extract_scenario_elements(query)

        return {
            "reasoning": f"–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–ø—Ä–æ—Å–∞: {query}",
            "scenario_type": "user_driven",
            "elements": scenario_elements,
            "approach": "dynamic_generation"
        }

    def _extract_scenario_elements(self, query: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —ç–ª–µ–º–µ–Ω—Ç—ã –¥–ª—è —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        elements = {
            "variables": [],
            "conditions": [],
            "outcomes": [],
            "timeframe": None
        }

        # –ü–æ–∏—Å–∫ —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π (–ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ)
        numbers = re.findall(r'\d+(?:\.\d+)?%', query)  # –ü—Ä–æ—Ü–µ–Ω—Ç—ã
        elements["variables"].extend(numbers)

        numbers = re.findall(r'\d+', query)  # –û–±—ã—á–Ω—ã–µ —á–∏—Å–ª–∞
        elements["variables"].extend([f"{num}" for num in numbers])

        # –ü–æ–∏—Å–∫ —É—Å–ª–æ–≤–∏–π
        if '–µ—Å–ª–∏' in query.lower() or '–µ—Å–ª–∏ –±—ã' in query.lower():
            elements["conditions"].append("—É—Å–ª–æ–≤–∏–µ")

        # –ü–æ–∏—Å–∫ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä–∞–º–æ–∫
        time_patterns = ['–¥–µ–Ω—å', '–Ω–µ–¥–µ–ª', '–º–µ—Å—è—Ü', '–≥–æ–¥']
        for pattern in time_patterns:
            if pattern in query.lower():
                elements["timeframe"] = pattern
                break

        return elements

    async def execute_scenario_analysis(self, query: str, solution_plan: Dict, context: Context) -> AnalysisResult:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∞–Ω–∞–ª–∏–∑ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö"""
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
        chroma_query = await self.chroma_manager.data_agent.generate_chroma_query(query, solution_plan, context)
        data = await self.chroma_manager.data_agent.execute_chroma_query(chroma_query)

        return AnalysisResult(
            query=query,
            chroma_query=chroma_query,
            data=data,
            reasoning_steps=[],
            insights=[],
            recommendations=[],
            confidence_score=0.7,
            validation_results={"is_valid": True, "confidence": 0.7}
        )

    async def generate_dynamic_scenarios(self, original_query: str, result: AnalysisResult, context: Context) -> Dict[
        str, Any]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞"""

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã —Å—Ü–µ–Ω–∞—Ä–∏—è –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
        scenario_elements = self._extract_scenario_elements(original_query)

        scenarios = {
            "baseline": {
                "description": "–¢–µ–∫—É—â–∏–π —Å—Ü–µ–Ω–∞—Ä–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞",
                "query_analysis": original_query,
                "elements": scenario_elements,
                "metrics": self._extract_metrics(result.data)
            },
            "scenarios": []
        }

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –∑–∞–ø—Ä–æ—Å–∞
        if scenario_elements["variables"]:
            for variable in scenario_elements["variables"]:
                scenario = await self._create_variable_scenario(original_query, variable, result.data)
                scenarios["scenarios"].append(scenario)

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö
        if result.data:
            data_scenarios = await self._create_data_driven_scenarios(result.data, original_query)
            scenarios["scenarios"].extend(data_scenarios)

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –≤ ChromaDB
        await self._save_scenarios_to_chroma(scenarios, original_query)

        return scenarios

    async def _create_variable_scenario(self, original_query: str, variable: str, data: List[Dict]) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–µ—Ç —Å—Ü–µ–Ω–∞—Ä–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –∏–∑ –∑–∞–ø—Ä–æ—Å–∞"""

        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –∏ —Å–æ–∑–¥–∞–Ω–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏—è
        if '%' in variable:
            # –ü—Ä–æ—Ü–µ–Ω—Ç–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
            percentage = float(variable.replace('%', ''))

            scenario = {
                "name": f"–ò–∑–º–µ–Ω–µ–Ω–∏–µ –Ω–∞ {variable}",
                "description": f"–ê–Ω–∞–ª–∏–∑ –≤–ª–∏—è–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏—è –Ω–∞ {variable} –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–ø—Ä–æ—Å–∞: {original_query}",
                "original_variable": variable,
                "parameters": {
                    "change_percentage": percentage / 100,
                    "direction": "—É–≤–µ–ª–∏—á–µ–Ω–∏–µ" if percentage > 0 else "—É–º–µ–Ω—å—à–µ–Ω–∏–µ"
                },
                "expected_outcomes": {
                    "impact_assessment": "–û—Ü–µ–Ω–∫–∞ –≤–ª–∏—è–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏—è",
                    "risk_analysis": "–ê–Ω–∞–ª–∏–∑ —Ä–∏—Å–∫–æ–≤",
                    "opportunity_identification": "–í—ã—è–≤–ª–µ–Ω–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π"
                },
                "confidence": 0.7,
                "risks": [
                    "–ù–µ–ª–∏–Ω–µ–π–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤",
                    "–í–Ω–µ—à–Ω–∏–µ —Ñ–∞–∫—Ç–æ—Ä—ã –º–æ–≥—É—Ç –ø–æ–≤–ª–∏—è—Ç—å –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç"
                ]
            }
        else:
            # –ß–∏—Å–ª–æ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
            scenario = {
                "name": f"–í–∞—Ä–∏–∞–Ω—Ç —Å {variable}",
                "description": f"–ê–Ω–∞–ª–∏–∑ —Å—Ü–µ–Ω–∞—Ä–∏—è —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–º {variable} –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–ø—Ä–æ—Å–∞: {original_query}",
                "parameters": {
                    "base_value": variable,
                    "multiplier": 1.2  # –ü—Ä–∏–º–µ—Ä multiplier
                },
                "expected_outcomes": {
                    "scenario_impact": "–í–ª–∏—è–Ω–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏—è –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç",
                    "optimization_potential": "–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"
                },
                "confidence": 0.6,
                "risks": [
                    "–û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö",
                    "–ü—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏—è –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–µ—Ç–æ—á–Ω—ã–º–∏"
                ]
            }

        return scenario

    async def _create_data_driven_scenarios(self, data: List[Dict], original_query: str) -> List[Dict[str, Any]]:
        """–°–æ–∑–¥–∞–µ—Ç —Å—Ü–µ–Ω–∞—Ä–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö"""

        scenarios = []

        if not data:
            return scenarios

        # –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        try:
            # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Å—Ö–æ–¥—Å—Ç–≤—É
            similarity_groups = {}
            for item in data:
                similarity = item.get("similarity", 0)
                if similarity > 0.8:
                    group = "highly_relevant"
                elif similarity > 0.6:
                    group = "moderately_relevant"
                else:
                    group = "low_relevance"

                if group not in similarity_groups:
                    similarity_groups[group] = []
                similarity_groups[group].append(item)

            # –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥—Ä—É–ø–ø
            for group_name, group_data in similarity_groups.items():
                if len(group_data) > 0:
                    scenario = {
                        "name": f"–°—Ü–µ–Ω–∞—Ä–∏–π {group_name}",
                        "description": f"–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö —Å {group_name} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å—é",
                        "parameters": {
                            "relevance_group": group_name,
                            "data_count": len(group_data),
                            "avg_similarity": np.mean([item.get("similarity", 0) for item in group_data])
                        },
                        "expected_outcomes": {
                            "group_analysis": f"–ê–Ω–∞–ª–∏–∑ –≥—Ä—É–ø–ø—ã {group_name}",
                            "pattern_identification": "–í—ã—è–≤–ª–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤",
                            "recommendation_generation": "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"
                        },
                        "confidence": 0.8,
                        "risks": [
                            "–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Ç–æ—á–Ω–æ–π",
                            "–î–∞–Ω–Ω—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–µ–ø–æ–ª–Ω—ã–º–∏"
                        ]
                    }
                    scenarios.append(scenario)

        except Exception as e:
            logger.error(f"Error creating data-driven scenarios: {e}")

        return scenarios

    def _extract_metrics(self, data: List[Dict]) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ –¥–∞–Ω–Ω—ã—Ö ChromaDB"""
        if not data:
            return {}

        try:
            metrics = {
                "total_count": len(data),
                "avg_similarity": np.mean([item.get("similarity", 0) for item in data]),
                "max_similarity": max([item.get("similarity", 0) for item in data]),
                "min_similarity": min([item.get("similarity", 0) for item in data]),
                "unique_collections": len(set([item.get("metadata", {}).get("collection", "") for item in data]))
            }

            return metrics
        except Exception as e:
            logger.error(f"Error extracting metrics: {e}")
            return {"total_count": len(data)}

    async def _save_scenarios_to_chroma(self, scenarios: Dict[str, Any], original_query: str):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –≤ ChromaDB"""
        try:
            # –°–æ–∑–¥–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
            documents = []
            metadatas = []
            ids = []

            for i, scenario in enumerate(scenarios.get("scenarios", [])):
                doc_content = f"Original Query: {original_query}\n"
                doc_content += f"Scenario: {scenario['name']}\n"
                doc_content += f"Description: {scenario['description']}\n"
                doc_content += f"Parameters: {json.dumps(scenario.get('parameters', {}), ensure_ascii=False)}\n"
                doc_content += f"Expected Outcomes: {json.dumps(scenario.get('expected_outcomes', {}), ensure_ascii=False)}\n"

                documents.append(doc_content)

                metadata = {
                    "original_query": original_query,
                    "scenario_name": scenario["name"],
                    "confidence": scenario.get("confidence", 0.5),
                    "timestamp": datetime.now().isoformat(),
                    "scenario_type": "dynamic"
                }
                metadatas.append(metadata)

                scenario_id = f"scenario_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{i}"
                ids.append(scenario_id)

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ ChromaDB
            if documents:
                self.chroma_manager.add_documents(
                    documents=documents,
                    metadatas=metadatas,
                    ids=ids,
                    collection_name='scenarios'
                )
                logger.info(f"Saved {len(documents)} scenarios to ChromaDB")

        except Exception as e:
            logger.error(f"Error saving scenarios to ChromaDB: {e}")


class ExplanationAgent:
    """–ê–≥–µ–Ω—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–Ω—Å–∞–π—Ç–æ–≤ –∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π"""

    def __init__(self, chroma_manager: ChromaDBManager):
        self.chroma_manager = chroma_manager

    async def generate_insights(self, result: AnalysisResult, context: Context) -> Dict[str, List[str]]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–Ω—Å–∞–π—Ç—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ChromaDB"""

        if not result.data:
            return {"insights": [], "recommendations": []}

        try:
            insights = []
            recommendations = []

            # –ë–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            insights.append(f"–ê–Ω–∞–ª–∏–∑ ChromaDB –∑–∞–≤–µ—Ä—à–µ–Ω. –ù–∞–π–¥–µ–Ω–æ {len(result.data)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.")

            # –ê–Ω–∞–ª–∏–∑ —Å—Ö–æ–¥—Å—Ç–≤–∞
            similarities = [item.get("similarity", 0) for item in result.data]
            if similarities:
                avg_similarity = np.mean(similarities)
                max_similarity = max(similarities)
                min_similarity = min(similarities)

                insights.append(f"–°—Ä–µ–¥–Ω—è—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {avg_similarity:.3f}")
                insights.append(f"–ù–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {max_similarity:.3f}")

                if max_similarity > 0.9:
                    insights.append("–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –≤—ã—Å–æ–∫–æ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã")
                elif max_similarity > 0.7:
                    insights.append("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —Ö–æ—Ä–æ—à—É—é —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å")
                else:
                    insights.append("–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É—Ç–æ—á–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å –¥–ª—è –ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")

            # –ê–Ω–∞–ª–∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            collections_used = set()
            time_ranges = []

            for item in result.data:
                metadata = item.get("metadata", {})
                if "collection" in metadata:
                    collections_used.add(metadata["collection"])

                if "timestamp" in metadata:
                    try:
                        time_ranges.append(datetime.fromisoformat(metadata["timestamp"]))
                    except:
                        pass

            if collections_used:
                insights.append(f"–î–∞–Ω–Ω—ã–µ –∏–∑ –∫–æ–ª–ª–µ–∫—Ü–∏–π: {', '.join(collections_used)}")

            if time_ranges:
                time_span = max(time_ranges) - min(time_ranges)
                insights.append(f"–í—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞–Ω–Ω—ã—Ö: {time_span.days} –¥–Ω–µ–π")

            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            if len(result.data) > 10:
                recommendations.append("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —à–∏—Ä–æ–∫–∏–π –æ—Ö–≤–∞—Ç —Ç–µ–º—ã")

            if avg_similarity < 0.6:
                recommendations.append("–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É—Ç–æ—á–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏")

            recommendations.extend([
                "–ò–∑—É—á–∏—Ç–µ –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∫–ª—é—á–µ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏",
                "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ–∏–ª—å—Ç—Ä—ã –ø–æ –¥–∞—Ç–µ –∏–ª–∏ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –¥–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤",
                "–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —Å–æ–∑–¥–∞–Ω–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"
            ])

            return {
                "insights": insights[:8],
                "recommendations": recommendations[:5]
            }
        except Exception as e:
            logger.error(f"Error generating insights: {e}")
            return {
                "insights": ["–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–Ω—Å–∞–π—Ç–æ–≤"],
                "recommendations": ["–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –≤ ChromaDB"]
            }


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Å–∏—Å—Ç–µ–º—ã
async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Å–∏—Å—Ç–µ–º—ã"""

    print("üöÄ –ó–ê–ü–£–°–ö –ü–†–û–î–£–ö–¢–ò–í–ù–û–ô –°–ò–°–¢–ï–ú–´ –¶–ò–§–†–û–í–û–ì–û –ê–ù–ê–õ–ò–¢–ò–ö–ê –° ChromaDB")
    print("=" * 80)

    # –°–æ–∑–¥–∞–µ–º —Å–∏—Å—Ç–µ–º—É
    digital_twin = AdvancedDigitalTwin()

    # –ü—Ä–∏–º–µ—Ä—ã –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    test_queries = [
        ("–ü–æ–∫–∞–∂–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ –ø—Ä–æ–µ–∫—Ç—É", QueryType.ANALYTICS),
        ("–ß—Ç–æ –µ—Å–ª–∏ —É–≤–µ–ª–∏—á–∏—Ç—å —Ä–µ—Å—É—Ä—Å—ã –Ω–∞ 50% –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è —Ä–∞–±–æ—Ç?", QueryType.SCENARIO),
        ("–ö–∞–∫–∏–µ —Ä–∏—Å–∫–∏ –µ—Å—Ç—å –≤ —Ç–µ–∫—É—â–µ–º –ø—Ä–æ–µ–∫—Ç–µ?", QueryType.ANALYTICS),
        ("–°—Ä–∞–≤–Ω–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Ä–∞–∑–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–æ–≤", QueryType.ANALYTICS),
        ("–ü—Ä–µ–¥—Å–∫–∞–∂–∏ —Å—Ä–æ–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—É—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö", QueryType.PREDICTION),
    ]

    for query, query_type in test_queries:
        print(f"\n{'=' * 60}")
        print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {query}")
        print(f"–¢–∏–ø: {query_type.value}")
        print(f"{'=' * 60}")

        try:
            result = await digital_twin.process_query(query, query_type=query_type)

            print(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
            print(f"- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π: {len(result.data)}")
            print(f"- –£—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏: {result.confidence_score:.2f}")
            print(f"- –í–∞–ª–∏–¥–∞—Ü–∏—è: {'–ü—Ä–æ–π–¥–µ–Ω–∞' if result.validation_results.get('is_valid') else '–ù–µ –ø—Ä–æ–π–¥–µ–Ω–∞'}")

            if result.insights:
                print(f"\n–ò–Ω—Å–∞–π—Ç—ã:")
                for insight in result.insights[:3]:
                    print(f"  ‚Ä¢ {insight}")

            if result.recommendations:
                print(f"\n–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
                for rec in result.recommendations[:2]:
                    print(f"  ‚Ä¢ {rec}")

            if result.scenario_analysis:
                print(f"\n–°—Ü–µ–Ω–∞—Ä–∏–∏:")
                for scenario in result.scenario_analysis.get("scenarios", [])[:2]:
                    print(f"  ‚Ä¢ {scenario['name']}: {scenario['description']}")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {e}")


if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
    asyncio.run(main())