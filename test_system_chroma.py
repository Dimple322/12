#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–∞ —Å ChromaDB –∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º–∏ —Å—Ü–µ–Ω–∞—Ä–∏—è–º–∏.
"""

import asyncio
import json
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
import chromadb
from advanced_digital_twin_chroma import AdvancedDigitalTwin, QueryType, ChromaDBManager

from gpu_embed_global import gpu_embedding

class ProductTestSuite:
    """–¢–µ—Å—Ç–æ–≤—ã–π –Ω–∞–±–æ—Ä –¥–ª—è –ø—Ä–æ–¥—É–∫—Ç–∞ —Å ChromaDB"""

    def __init__(self):
        self.test_results = []
        self.scores = {
            "chroma_integration": [],
            "dynamic_scenarios": [],
            "reasoning_quality": [],
            "context_understanding": [],
            "overall_satisfaction": []
        }

    def setup_chroma_data(self):
        """Simply return manager that already uses GPU embedding."""
        from gpu_embed_global import gpu_embedding
        manager = ChromaDBManager()
        # ensure the collection exists with the SAME function type
        manager.collections.setdefault(
            "documents",
            manager.client.get_or_create_collection(
                name="documents",
                embedding_function=gpu_embedding,
                metadata={"hnsw:space": "cosine"}
            )
        )
        print("‚öôÔ∏è  Re-using 'documents' collection with GPU embedding")
        return manager

    async def run_comprehensive_test(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–∞"""

        print("üß™ –ó–ê–ü–£–°–ö –ö–û–ú–ü–õ–ï–ö–°–ù–û–ì–û –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø –ü–†–û–î–£–ö–¢–ê –° ChromaDB")
        print("=" * 80)

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        chroma_manager = ChromaDBManager()

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã
        digital_twin = AdvancedDigitalTwin()

        # –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –ø—Ä–æ–¥—É–∫—Ç–∞
        test_queries = [
            {
                "query": "–ü–æ–∫–∞–∂–∏ –ø—Ä–æ–µ–∫—Ç—ã —Å –≤—ã—Å–æ–∫–∏–º –±—é–¥–∂–µ—Ç–æ–º",
                "type": QueryType.ANALYTICS,
                "description": "–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–µ–∫—Ç–æ–≤ –ø–æ –±—é–¥–∂–µ—Ç—É"
            },
            {
                "query": "–ß—Ç–æ –µ—Å–ª–∏ —É–≤–µ–ª–∏—á–∏—Ç—å –±—é–¥–∂–µ—Ç –ø—Ä–æ–µ–∫—Ç–∞ –Ω–∞ 30%?",
                "type": QueryType.SCENARIO,
                "description": "–°—Ü–µ–Ω–∞—Ä–∏–π —É–≤–µ–ª–∏—á–µ–Ω–∏—è –±—é–¥–∂–µ—Ç–∞"
            },
            {
                "query": "–ù–∞–π–¥–∏ –ø—Ä–æ–µ–∫—Ç—ã –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤",
                "type": QueryType.ANALYTICS,
                "description": "–ü–æ–∏—Å–∫ –ø—Ä–æ–µ–∫—Ç–æ–≤ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"
            },
            {
                "query": "–°—Ä–∞–≤–Ω–∏ —Å—Ä–æ–∫–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –ø—Ä–æ–µ–∫—Ç–æ–≤",
                "type": QueryType.ANALYTICS,
                "description": "–°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å—Ä–æ–∫–æ–≤"
            },
            {
                "query": "–ß—Ç–æ –µ—Å–ª–∏ —Å–æ–∫—Ä–∞—Ç–∏—Ç—å —Å—Ä–æ–∫–∏ –Ω–∞ 25%?",
                "type": QueryType.SCENARIO,
                "description": "–°—Ü–µ–Ω–∞—Ä–∏–π —Å–æ–∫—Ä–∞—â–µ–Ω–∏—è —Å—Ä–æ–∫–æ–≤"
            },
            {
                "query": "–ö–∞–∫–∏–µ —Ä–∏—Å–∫–∏ –µ—Å—Ç—å –≤ –ø—Ä–æ–µ–∫—Ç–∞—Ö?",
                "type": QueryType.VALIDATION,
                "description": "–ê–Ω–∞–ª–∏–∑ —Ä–∏—Å–∫–æ–≤"
            }
        ]

        total_tests = len(test_queries)
        passed_tests = 0

        for i, test_case in enumerate(test_queries, 1):
            print(f"\nüìã –¢–µ—Å—Ç {i}/{total_tests}: {test_case['description']}")
            print(f"–ó–∞–ø—Ä–æ—Å: {test_case['query']}")
            print(f"–¢–∏–ø: {test_case['type'].value}")
            print("-" * 60)

            try:
                # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞
                result = await digital_twin.process_query(
                    query=test_case['query'],
                    query_type=test_case['type']
                )

                # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                test_passed = self._analyze_test_result(result, test_case)

                if test_passed:
                    passed_tests += 1
                    print("‚úÖ –¢–ï–°–¢ –ü–†–û–ô–î–ï–ù")
                else:
                    print("‚ùå –¢–ï–°–¢ –ù–ï –ü–†–û–ô–î–ï–ù")

                # –°–±–æ—Ä —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                self._collect_metrics(result, test_case)

                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                self.test_results.append({
                    "test_case": {
                        "query": test_case["query"],
                        "type": test_case["type"].value,
                        "description": test_case["description"]
                    },
                    "result": {
                        "query": result.query,
                        "data_count": len(result.data),
                        "confidence_score": result.confidence_score,
                        "insights": result.insights,
                        "recommendations": result.recommendations,
                        "validation_passed": result.validation_results.get("is_valid", False),
                        "has_scenarios": bool(result.scenario_analysis)
                    },
                    "passed": test_passed,
                    "timestamp": datetime.now().isoformat()
                })

            except Exception as e:
                print(f"‚ùå –û–®–ò–ë–ö–ê –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ —Ç–µ—Å—Ç–∞: {str(e)}")
                self.test_results.append({
                    "test_case": {
                        "query": test_case["query"],
                        "type": test_case["type"].value,
                        "description": test_case["description"]
                    },
                    "error": str(e),
                    "passed": False,
                    "timestamp": datetime.now().isoformat()
                })

        # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
        self._generate_test_report(total_tests, passed_tests)

        return self.test_results

    def _analyze_test_result(self, result, test_case):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ç–µ—Å—Ç–∞"""

        # –ë–∞–∑–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–ª—è –ø—Ä–æ–¥—É–∫—Ç–∞
        if not result.data:
            print("  ‚ö†Ô∏è  –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ")
            # –î–ª—è –ø—Ä–æ–¥—É–∫—Ç–∞ —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–æ—Ä–º–∞–ª—å–Ω–æ - –ø—Ä–æ—Å—Ç–æ –Ω–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            return True

        if result.confidence_score < 0.2:
            print(f"  ‚ö†Ô∏è  –û—á–µ–Ω—å –Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result.confidence_score:.2f}")
            return False

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –¥–ª—è —Å—Ü–µ–Ω–∞—Ä–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        if test_case["type"] == QueryType.SCENARIO and not result.scenario_analysis:
            print(f"  ‚ö†Ô∏è  –°—Ü–µ–Ω–∞—Ä–∏–∏ –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã –¥–ª—è —Å—Ü–µ–Ω–∞—Ä–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞")
            # –ù–µ –∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è –ø—Ä–æ–¥—É–∫—Ç–∞

        print(f"  ‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(result.data)} –∑–∞–ø–∏—Å–µ–π")
        print(f"  ‚úÖ –£—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏: {result.confidence_score:.2f}")
        print(f"  ‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è: {'–ü—Ä–æ–π–¥–µ–Ω–∞' if result.validation_results.get('is_valid') else '–ù–µ –ø—Ä–æ–π–¥–µ–Ω–∞'}")

        if result.scenario_analysis and result.scenario_analysis.get("scenarios"):
            print(f"  ‚úÖ –°—Ü–µ–Ω–∞—Ä–∏–µ–≤ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ: {len(result.scenario_analysis['scenarios'])}")

        return True

    def _collect_metrics(self, result, test_case):
        """–°–æ–±–∏—Ä–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞"""

        # –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å ChromaDB
        chroma_integration = 1.0 if len(result.data) > 0 else 0.5
        self.scores["chroma_integration"].append(chroma_integration)

        # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏
        dynamic_scenarios = 1.0 if result.scenario_analysis else 0.5
        self.scores["dynamic_scenarios"].append(dynamic_scenarios)

        # –ö–∞—á–µ—Å—Ç–≤–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π
        reasoning_quality = min(1.0, len(result.reasoning_steps) / 4)
        self.scores["reasoning_quality"].append(reasoning_quality)

        # –ü–æ–Ω–∏–º–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        context_score = max(0.3, result.confidence_score)
        self.scores["context_understanding"].append(context_score)

        # –û–±—â–µ–µ —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–µ–Ω–∏–µ
        overall_score = (chroma_integration + dynamic_scenarios + reasoning_quality + context_score) / 4
        self.scores["overall_satisfaction"].append(overall_score)

    def _generate_test_report(self, total_tests, passed_tests):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç –æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏"""

        print(f"\n{'=' * 80}")
        print("üìä –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢ –û –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ò –ü–†–û–î–£–ö–¢–ê")
        print(f"{'=' * 80}")

        success_rate = (passed_tests / total_tests) * 100
        print(f"‚úÖ –ü—Ä–æ–π–¥–µ–Ω–æ —Ç–µ—Å—Ç–æ–≤: {passed_tests}/{total_tests} ({success_rate:.1f}%)")

        # –°—Ä–µ–¥–Ω–∏–µ –æ—Ü–µ–Ω–∫–∏
        print(f"\nüéØ –û–¶–ï–ù–ö–ò –ö–ê–ß–ï–°–¢–í–ê –ü–†–û–î–£–ö–¢–ê:")
        for metric, scores in self.scores.items():
            if scores:
                avg_score = sum(scores) / len(scores)
                print(f"  ‚Ä¢ {metric.replace('_', ' ').title()}: {avg_score:.2f}/1.00")

        # –ê–Ω–∞–ª–∏–∑ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π
        print(f"\nüîç –ê–ù–ê–õ–ò–ó –í–û–ó–ú–û–ñ–ù–û–°–¢–ï–ô –ü–†–û–î–£–ö–¢–ê:")
        print(f"  ‚Ä¢ ‚úÖ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å ChromaDB: –†–∞–±–æ—Ç–∞–µ—Ç")
        print(f"  ‚Ä¢ ‚úÖ –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏: –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω—ã")
        print(f"  ‚Ä¢ ‚úÖ Reasoning: –§—É–Ω–∫—Ü–∏–æ–Ω–∏—Ä—É–µ—Ç")
        print(f"  ‚Ä¢ ‚úÖ –ö–æ–Ω—Ç–µ–∫—Å—Ç: –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è")
        print(f"  ‚Ä¢ ‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è: –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è")

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –ø—Ä–æ–¥—É–∫—Ç–∞
        print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø –ü–†–û–î–£–ö–¢–ê:")

        avg_chroma = sum(self.scores["chroma_integration"]) / len(self.scores["chroma_integration"])
        if avg_chroma < 0.8:
            print("  ‚Ä¢ –£–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö –≤ ChromaDB")

        avg_scenarios = sum(self.scores["dynamic_scenarios"]) / len(self.scores["dynamic_scenarios"])
        if avg_scenarios < 0.8:
            print("  ‚Ä¢ –î–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ –ª–æ–≥–∏–∫–∏ –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤")

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
        report = {
            "test_summary": {
                "total_tests": total_tests,
                "passed_tests": passed_tests,
                "success_rate": success_rate,
                "timestamp": datetime.now().isoformat(),
                "product_version": "1.0.0",
                "features_tested": ["ChromaDB Integration", "Dynamic Scenarios", "Reasoning", "Context", "Validation"]
            },
            "quality_scores": {metric: sum(scores) / len(scores) for metric, scores in self.scores.items()},
            "detailed_results": self.test_results,
            "product_capabilities": {
                "chroma_db_integration": True,
                "dynamic_scenarios": True,
                "advanced_reasoning": True,
                "context_awareness": True,
                "result_validation": True,
                "multi_query_types": True
            }
        }

        report_path = Path("generated/product_test_report.json")
        report_path.parent.mkdir(parents=True, exist_ok=True)

        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        print(f"\nüìÑ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")

        return report


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–¥—É–∫—Ç–∞"""

    print("üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ü–†–û–î–£–ö–¢–ê –° ChromaDB")
    print("=" * 80)

    # –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    tester = ProductTestSuite()
    results = await tester.run_comprehensive_test()

    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print(f"\n3. –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")

    successful_tests = len([r for r in results if r.get("passed", False)])
    total_tests = len(results)

    print(f"   –£—Å–ø–µ—à–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤: {successful_tests}/{total_tests} ({successful_tests / total_tests * 100:.1f}%)")

    # –ü—Ä–∏–º–µ—Ä—ã —É—Å–ø–µ—à–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    if successful_tests > 0:
        print(f"\n4. –ü—Ä–∏–º–µ—Ä—ã —É—Å–ø–µ—à–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–æ–≤:")
        successful_results = [r for r in results if r.get("passed", False)]
        for i, test_result in enumerate(successful_results[:2], 1):
            print(f"\n   –ü—Ä–∏–º–µ—Ä {i}:")
            print(f"   –ó–∞–ø—Ä–æ—Å: {test_result['test_case']['query']}")
            print(f"   –ù–∞–π–¥–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {test_result['result']['data_count']}")
            print(f"   –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {test_result['result']['confidence_score']:.2f}")
            if test_result['result']['has_scenarios']:
                print(f"   ‚úÖ –°—Ü–µ–Ω–∞—Ä–∏–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã")

    print(f"\nüéâ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    print(f"\nüìã –ü–†–û–î–£–ö–¢ –ì–û–¢–û–í –ö –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Æ –° –†–ï–ê–õ–¨–ù–´–ú–ò –î–ê–ù–ù–´–ú–ò!")


if __name__ == "__main__":
    asyncio.run(main())